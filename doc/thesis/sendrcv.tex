\section{Send Receive} \label{sec:conn:send}\label{sendrcv}
\subsection{Design} \label{sendrcv-design}
The Send Receive based protocol is by far the simplest, as the send and receive verbs basically already provide the 
message passing interface we want. There are still multiple ways to implement such a protocol and a few pitfalls 
we need to address to get good performance.

\paragraph{} We presented the basic function of the send verb in Section \ref{sec:bg:send}. It allows the sender to transmit 
a message to the receiver, without any additional information, as long as the receiver has posted a receiver buffer that is 
large enough to receive the message. To transform this verb to a fully functioning connection we need two basic things. 
Some kind of \emph{receive buffer management} that allows the receiver to receive multiple messages at the same time, 
and to get any reasonable performance we need to be able to send multiple messages asynchronously.

\subsubsection{Sender} 
The sender assumes that the receiver is always ready to receive the message and has at least one receive buffer posted.
The Sender has only two essential methods:

\begin{lstlisting}  
    // Takes a registered region containing the message
    // Posts a signaled send work request to the QP
    // Returns the unique wr_id associated with the WR 
    uint64_t SendAsync(SendRegion reg);

    // Polls the CQ until there is completion event 
    // associated with the given id.
    void Wait(uint64_t id);

\end{lstlisting}

This allows us to queue multiple messages before waiting for them to complete. In practice it is very important to keep the
sending pipeline full to get good performance. This kind of \emph{unacknowledged messages} can increase throughout by a factor
of 5 or more.

\paragraph{} We are able to wait for a specific work request to complete by issuing monotonically increasing IDs. We store the
last ID with a matching completion event. If we try to wait on a lower ID we know we already received a matching completion 
event prior, because of the in order guarantees of RDMA.\comment{Maybe cite something?} If the provided ID is higher then the
last seen ID, we will poll the completion queue until we receive one with a matching \code{wr\_id}.

This approach will eventually lead to an overflow, but given our observed maximum message rate we do not expect to see this 
happen in the next 10 thousand years.


\paragraph{Batching} As briefly mentioned in Section \ref{sec:bg:send} we can post multiple work request at the same time. 
This \emph{Doorbell batching} reduces the number of generated MMIOs~\cite{anuj-guide}, reduces the CPU load and can in turn 
drastically improve bandwidth if the connection is send-side CPU bottleneck. We observed a performance increase by up to 
a factor of two. It is however questionable if this connection level batching is the right approach when using the 
\emph{Reliable Connection} that we evaluated. With RC all messages need to end up at the same receiver meaning application 
level batching should be possible and we observed that sending larger messages will outperform sending small messages in 
batches.

\paragraph{Inline Sending} \todo{We should probably add some kind of benchmarks for this.}

\subsubsection{Receiver}

The receiver always needs to have at least one posted receive buffer. We achieve this by having an array of posted receive 
buffers. When receiving a new message we return the corresponding receive buffer. As soon as the application is done processing
the message, it will have to mark it as free which will repost the corresponding buffer.

\begin{lstlisting}  
    // Waits for the next CQE on the receive CQ
    // Returns the matching receive region
    ReceiveRegion Receive();

    // Marks the given receive region as free
    // to be reused and will post a receive
    // request for this region
    void Free(ReceiveRegion reg);

\end{lstlisting}

Slow processing of messages can still stall the sender, but by having multiple receive buffer it allows us to have numerous 
\emph{in-flight messages} which improves performance drastically.

\paragraph{} It is important that we note here that in production systems there needs to be a way for the sender to whether 
enough receive buffers are ready. If there is no posted receive buffer when a message is received the receiver will generate
a so called \emph{reader not ready} error. This will either cause a large back off for the sender or even cause the connection
to break.

We observed this problem specifically for N:1 communication. This can be mitigated to some extend by optimizing receiving and
reposting buffers through batching.

\paragraph{Batching} As described there are significant penalties if the receiver is not able to keep up and stalls the sender.
This can be mitigated a little optimizing the receiver. For one instead of polling one receive CQ at a time we poll up to 32
at a time into a array of CQEs. We observed in microbenchmarks that this can improve the observed throughput by nearly half. By
batching the receive work requests we can further improve throughput similarly to batching send requests.

\paragraph{Shared Receive Queues} By having an array of $k$ posted receive buffers for each receiver the memory reserved for 
receiving messages can grow quite large. If a node has an open connection to $N$ other nodes it will need to reserve 
$N*k*max\_msg\_size$ Bytes, even if the total request volume is quite small (i.e. we expect only burst of $k$ messages but 
from different nodes at different times).

We can reduce the total memory usage by using \emph{Shared Receive Queues (SRQ)}. As the name already tells us SRQs allow us
share receive queues between multiple QPs. This means we can reuse a single group of receive queues for multiple connections.
This means the total memory usage does not grow with $N$.

Its worth noting that the usage of SRQs does not impact completion queues. The completion event for consuming a posted receive
buffer still ends up in the CQ of the corresponding QP.

One major change with using an SRQ is that we do not submit receive work request to each of the QPs but to the single SRQ. This
means that we will either have to introduce locking to access the SRQ, which introduces a significant performance penalty or 
delegate the posting of the receive buffer to a single thread. Instead of reposting the buffer themselves each connection 
enqueues the id to the to be posted buffer to a queue. The single reposting thread will dequeue it and repost it. This also
allows us to have central batching for reposting the buffers.

\paragraph{Single Receiver} It is very common to have an N:1 communication pattern where a single server receives messages 
from multiple clients. This could be achieved by simply round-robin over the $N$ connections. For this connection however 
we used the fact that we can associate a singe Completion Queue with multiple Queue Pairs. This means if we are in a
\emph{single receiver mode} all receive completion events will end up in a single CQ. Allowing us to poll a single queue to
receive a message from $N$ different sender.

Especially if we are not using an SRQ we will have to know by which QP this message was received by as we will need to repost
the buffer to it. We can get the 32 bit QP number from the Completion Queue Event, which identifies the Queue Pair. 

\subsection{Evaluation}

\subsubsection{Model Parameters}

We are using the model presented in Section \ref{sec:perf-model}, with the specific protocol 
we can look at what each of these parameters represents and allows us to at least give a qualitative understanding.


\begin{itemize}
  \item $L$: represents the latency of moving a byte from the senders memory to the receivers memory. It includes the 
    network latency as well as two DMA access latencies.
  \item $G$: is the bandwidth between the sender and receiver, which we expect to be equal to the maximum network bandwidth.
  \item $g_{snd}$: the minimum time interval between consecutive message transmissions. In this case we expect this to be 
    equal to polling the \emph{send completion queue}. If we do not allow for sufficient unacknowledged messages, this will
    also include waiting for these messages to be acknowledged.
  \item $o_{snd}$: the \emph{send overhead} for the CPU. This will be the time of posting a send request.
  \item $o_{nsnd}$: the \emph{send NIC overhead}, which is the overhead of sending a single message for the NIC.
  \item $o_{nrcv}$: the \emph{receive NIC overhead}. This represents the overhead of receiving a single message and the cost of 
    consuming a receive buffer and generating a \emph{WQE}.
  \item $o_{rcv}$: the \emph{receive overhead} for the CPU. This represents the overhead of polling the \emph{CQ}.
  \item $g_{rcv}$: the \emph{receive gap}. In this case we expect this to represent the cost of reposting a receive buffer.
\end{itemize}


In practice it is fairly hard to asses some of these parameters. \todo{some sentences on what we would expect}


\begin{figure}[h]
\includegraphics[width=1\textwidth]{send-lat-msgsize.png}
\caption{Evaluation of the Send Receive latency between two nodes and our performance model}
\label{fig:plot-sndrcv-lat}
\end{figure}

\subsubsection{Latency} \todo{filler}. For point to point latency, our model basically reduces to the $\alpha$-$\beta$ model. We
have the bandwidth $G$ and a bunch of overheads that are unrelated to the size of the message $k$.

$$
t \geq o_{snd} + o_{nsnd}  + (k-1)G + L + o_{nrcv} + o_{rcv}
$$

Figure \ref{fig:plot-sndrcv-lat} shows the latency the latency of sending a message of varying sizes using our send receive 
implementation. In our benchmark a single client and server 
perform a \emph{ping-pong}. With that we mean that the client initiates the communication and measures the RTT and the server
mirrors all received packages. We then take half of this RTT as our measurement of latency.

\todo{SRQ?}

Figure \ref{fig:plot-sndrcv-lat} also evaluates or model. Given that there is quite a lot of noise, our simplified model fits
the observed data well. \todo{Except it doesn't really.. DARE uses a different B for messages over MTU. Why? Would this 
fix the model?}. 

\subsubsection{Bandwidth}
\todo{filler, what do these terms actually mean?}


$$
bw \leq \max ( \frac{k}{o_{snd} + g_{snd}}, \frac{k}{o_{nsnd} + (k-1)G}, \frac{k}{o_{nrcv} + (k-1)G}, \frac{k}{o_{rcv} + g_{rcv}})
$$

So for our model comes down to finding the bottleneck. Our first finding has to be that if we do not allow for multiple 
unacknowledged messages, we are severely bottleneck by $\frac{k}{o_{snd} + g_{snd}}$ as $g_{snd} > 2L$. Figure 
\ref{fig:plot-sndrcv-bw-unack} shows this very well. Given a fixed message size of 16 bytes and no batching, the measured 
throughput increases linearly until we allow for about 32 unacknowledged messages. Afterwards performance does not further 
increase as we are bottleneck by something else. \todo{handwavy explanation why we now expect 32 to be enough for larger 
message sizes}

\begin{figure}[h]
\begin{subfigure}[b]{0.49\textwidth}
  \centering
  \includegraphics[width=1\textwidth]{send-bw-unack.png}
  \caption{Bandwidth with message size of 16 bytes with varying number of unacknowledged messages}
  \label{fig:plot-sndrcv-bw-unack}
\end{subfigure}
\begin{subfigure}[b]{0.49\textwidth}
  \centering
  \includegraphics[width=1\textwidth]{send-bw-batch.png}
  \caption{Bandwidth with message size of 16 bytes with varying batch size \todo{redo measurement for 64 unack}}
  \label{fig:plot-sndrcv-bw-batch}
\end{subfigure}
\end{figure}


\todo{Reference final bw graph with three benchmarks. Without unack, with unack, with unack and batch. As well as our model}

We can clearly see that we are sill bottlenecked by something other then the device and network. We can rule out that we are
bottlenecked by the receiver by setting \texttt{rnr\_retry\_count} to zero, which means that if any incoming messages is unable
to find a posted receive buffer, it will fail and the sender will not retry it. This means we will immediately notice if 
the receiver cannot keep up. At least for a simple 1:1 communication this does not seem to be the case.

This leaves us with the overhead $o_{snd}$ that seems to bottleneck us for smaller messages. We can reduce this overhead by 
posting multiple send requests in a batch. \todo{I remember some paper explicitly saying that batching for RC is not reasonable
as the messages have the same destination. Find this and write something why this can still be helpful in message broker like
situations where a single thread handles messages for multiple threads. Or other situations where application level batching 
is not practical}

Figure \ref{fig:plot-sndrcv-bw-batch} shows the throughout given a fixed message size of 16 bytes with varying batch sizes for
multiple numbers of unacknowledged messages. We can see that that throughout increases more or less linearly but we do not seem
to gain any throughput with a batch size larger than 8. We also notice that we are quickly bottleneck again by the amount of 
unacknowledged messages. When increasing both batch size and the number of unacknowledged messages we seem to hit
another bottleneck.

With adjusted batch size of 8 and a maximum number of unacknowledged messages of 256 we now seem to bottlenecked by the 
device itself. In Figure \ref{fig:plot-sndrcv-bw} we can that the measurements for the batched connections align fairly 
well with what our model predicts when we are bottlenecked by the sending device. \todo{Except it doesn't. What am I doing wrong?}

\begin{figure}[h]
\includegraphics[width=1\textwidth]{send-bw-msgsize.png}
\caption{Evaluation of the Send Receive bandwidth between two nodes and our performance model}
\label{fig:plot-sndrcv-bw}
\end{figure}


\subsubsection{Multithreading}

We can see that when we have single point to point connection, we are almost always limited by the sender and the 
amount of requests we are able to issue. In practice however we usually do not have a such a simple setup, but we
need to send and receive from and to multiple different nodes. This means each nodes needs to handle multiple open
connections.

To evaluate the performance of our Send Receive protocol with multiple open connections we again us two nodes. Each 
running \todo{Specs}. On each node we run $T$ threads, each thread $t_k$ opens a connection with the corresponding 
thread on the other node, giving us a total of $T$ connection sharing the same NIC. We evaluate the throughput for 
three different message sizes which had different characteristics in our single threaded evaluation: 16 bytes, 
which was heavily bound by how fast we could post send requests, 512 bytes, which was also limited by the sender
but less extreme, and 8192 bytes, which is limited by the actual device bandwidth. We do not perform any sender side
batching but allow for 64 unacknowledged messages, keeping the pipeline full.


Figure \ref{fig:plot-sndrcv-bw-thread} shows the total throughput of all connections with varying number of connections.
We can easily see that for large messages we keep being bottlenecked by the device bandwidth of 100 Gbit/s. For smaller
messages first increases linearly until we hit a bottleneck of ?? MOp/s. This seems to be the total throughput of the 
receiving NIC \todo{Or sending?}. This is significantly higher than our maximum throughput seen for a single connection,
this can be attributed to the usage of multiple processing units~\cite{}


Figure \ref{fig:plot-sndrcv-bw-thread-srq} shows the same data when using a shared receive queue (SRQ) to share memory
between the connections. It shows that all receivers sharing an SRQ are limited by it to a maximum of 2 MOp/s. This is 
drastically lower than without any resource sharing and heavily limits the performance for small messages. This seems
to be a limit of the receivers NIC, or in our model this means that $o_{nrcv}$ is significantly larger when using a 
SRQ. \todo{This does not really fit with what we observe in the microbenchmark. How do we explain this?}


\subsubsection{Single Receiver}

One of the most prevalent communication pattern is the N:1 configuration, where a single server handles the messages
of multiple clients.

\subsection{Result}


